import os
import json
import numpy as np
import faiss
from google.oauth2 import service_account
from googleapiclient.discovery import build
import openai
from dotenv import load_dotenv
import base64

# === åˆæœŸè¨­å®š ===
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# === ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š ===
SPREADSHEET_ID = '1ApH-A58jUCZSKwTBAyuPZlZTNsv_2RwKGSqZNyaHHfk'
RANGE_NAME = 'FAQ!A1:C'  # Aåˆ—:question, Båˆ—:answer, Cåˆ—:categoryï¼ˆä»»æ„ï¼‰
SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# GOOGLE_CREDENTIALSï¼ˆbase64å½¢å¼ï¼‰ã‚’å¾©å·
credentials_json = base64.b64decode(os.environ["GOOGLE_CREDENTIALS"]).decode("utf-8")
credentials_info = json.loads(credentials_json)
credentials = service_account.Credentials.from_service_account_info(
    credentials_info, scopes=SCOPES
)

# Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
sheet_service = build('sheets', 'v4', credentials=credentials).spreadsheets()
result = sheet_service.values().get(
    spreadsheetId=SPREADSHEET_ID,
    range=RANGE_NAME
).execute()
values = result.get('values', [])

# === faq.json ã®æ›´æ–° ===
faq_list = []
for i, row in enumerate(values[1:]):  # 1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼
    if len(row) >= 2 and row[0].strip() and row[1].strip():
        faq = {
            'question': row[0].strip(),
            'answer': row[1].strip()
        }
        if len(row) >= 3 and row[2].strip():
            faq['category'] = row[2].strip()
        faq_list.append(faq)

os.makedirs('data', exist_ok=True)
faq_path = 'data/faq.json'
with open(faq_path, 'w', encoding='utf-8') as f:
    json.dump(faq_list, f, ensure_ascii=False, indent=2)

print(f"âœ… {faq_path} ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")

# === knowledge.json èª­ã¿è¾¼ã¿ ===
with open("data/knowledge.json", "r", encoding="utf-8") as f:
    knowledge_dict = json.load(f)
knowledge_contents = [
    f"{category}ï¼š{text}"
    for category, texts in knowledge_dict.items()
    for text in texts
]

# === metadata èª­ã¿è¾¼ã¿ï¼ˆä»»æ„ï¼‰===
metadata_note = ""
metadata_path = "data/metadata.json"
if os.path.exists(metadata_path):
    with open(metadata_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)
        metadata_note = f"ã€ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã€‘{metadata.get('title', '')}ï¼ˆç¨®é¡ï¼š{metadata.get('type', '')}ã€å„ªå…ˆåº¦ï¼š{metadata.get('priority', '')}ï¼‰"

# === ãƒ™ã‚¯ãƒˆãƒ«å†ç”Ÿæˆ ===
EMBED_MODEL = "text-embedding-3-small"
search_corpus = [item["question"] for item in faq_list] + knowledge_contents + [metadata_note]

def get_embedding(text):
    response = openai.embeddings.create(model=EMBED_MODEL, input=text)
    return np.array(response.data[0].embedding, dtype="float32")

print("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†ç”Ÿæˆã—ã¦ã„ã¾ã™...")
vector_data = np.array([get_embedding(text) for text in search_corpus], dtype="float32")

dimension = vector_data.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(vector_data)

# === ä¿å­˜ ===
np.save("data/vector_data.npy", vector_data)
faiss.write_index(index, "data/index.faiss")

print("âœ… ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã¨FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
