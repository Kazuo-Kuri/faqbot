import os
import json
import numpy as np
import faiss
from google.oauth2 import service_account
from googleapiclient.discovery import build
import openai

# === ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã®ã¿ .env ã‚’èª­ã¿è¾¼ã‚€ ===
if os.getenv("GITHUB_ACTIONS") != "true":
    from dotenv import load_dotenv
    load_dotenv()

# === OpenAI APIã‚­ãƒ¼è¨­å®š ===
openai.api_key = os.getenv("OPENAI_API_KEY")

# === credentials.json ã‚’ç›´æ¥èª­ã¿è¾¼ã¿ ===
SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']
with open("credentials.json", "r", encoding="utf-8") as f:
    credentials_info = json.load(f)
credentials = service_account.Credentials.from_service_account_info(
    credentials_info, scopes=SCOPES
)

# === ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š ===
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID") or '1ApH-A58jUCZSKwTBAyuPZlZTNsv_2RwKGSqZNyaHHfk'
RANGE_NAME = 'FAQ!A1:C'

sheet_service = build('sheets', 'v4', credentials=credentials).spreadsheets()
result = sheet_service.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()
values = result.get('values', [])

# === faq.json ã‚’ç”Ÿæˆ ===
faq_list = []
for row in values[1:]:  # 1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼
    if len(row) >= 2 and row[0].strip() and row[1].strip():
        entry = {"question": row[0].strip(), "answer": row[1].strip()}
        if len(row) >= 3 and row[2].strip():
            entry["category"] = row[2].strip()
        faq_list.append(entry)

os.makedirs("data", exist_ok=True)
with open("data/faq.json", "w", encoding="utf-8") as f:
    json.dump(faq_list, f, ensure_ascii=False, indent=2)

print("âœ… data/faq.json ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

# === knowledge.json ã‚’èª­ã¿è¾¼ã¿ ===
with open("data/knowledge.json", "r", encoding="utf-8") as f:
    knowledge_dict = json.load(f)
knowledge_contents = [
    f"{category}ï¼š{text}"
    for category, texts in knowledge_dict.items()
    for text in texts
]

# === metadataï¼ˆä»»æ„ï¼‰===
metadata_note = ""
metadata_path = "data/metadata.json"
if os.path.exists(metadata_path):
    with open(metadata_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)
        metadata_note = f"ã€ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã€‘{metadata.get('title', '')}ï¼ˆç¨®é¡ï¼š{metadata.get('type', '')}ã€å„ªå…ˆåº¦ï¼š{metadata.get('priority', '')}ï¼‰"

# === ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†ç”Ÿæˆ ===
EMBED_MODEL = "text-embedding-3-small"
search_corpus = [item["question"] for item in faq_list] + knowledge_contents + [metadata_note]

def get_embedding(text):
    response = openai.embeddings.create(model=EMBED_MODEL, input=text)
    return np.array(response.data[0].embedding, dtype="float32")

print("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†ç”Ÿæˆã—ã¦ã„ã¾ã™...")
vector_data = np.array([get_embedding(text) for text in search_corpus], dtype="float32")

dimension = vector_data.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(vector_data)

# === ä¿å­˜ ===
np.save("data/vector_data.npy", vector_data)
faiss.write_index(index, "data/index.faiss")

print("âœ… ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã¨FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
