# app.py
import os
import json
import time
import base64
from datetime import datetime
from dotenv import load_dotenv

# ğŸ›¡ï¸ proxy ç’°å¢ƒå¤‰æ•°ã®å‰Šé™¤
for var in ["HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy"]:
    os.environ.pop(var, None)

from flask import Flask, request, jsonify
from flask_cors import CORS
from google.oauth2 import service_account
from googleapiclient.discovery import build
from openai import OpenAI
import faiss
import numpy as np
from product_film_matcher import ProductFilmMatcher

load_dotenv()

app = Flask(__name__)
CORS(app)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´
session_histories = {}
HISTORY_TTL = 1800

def get_session_history(session_id):
    now = time.time()
    session = session_histories.get(session_id)
    if not session or now - session["last_active"] > HISTORY_TTL:
        session_histories[session_id] = {"last_active": now, "history": []}
    else:
        session_histories[session_id]["last_active"] = now
    return session_histories[session_id]["history"]

def add_to_session_history(session_id, role, content):
    history = get_session_history(session_id)
    history.append({"role": role, "content": content})
    if len(history) > 10:
        history[:] = history[-10:]

# FAQ & knowledge ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
with open("data/faq.json", encoding="utf-8") as f:
    faq_items = json.load(f)
faq_questions = [item["question"] for item in faq_items]
faq_answers = [item["answer"] for item in faq_items]

with open("data/knowledge.json", encoding="utf-8") as f:
    knowledge_dict = json.load(f)
knowledge_contents = [
    f"{category}ï¼š{text}" for category, texts in knowledge_dict.items() for text in texts
]

metadata_note = ""
metadata_path = "data/metadata.json"
if os.path.exists(metadata_path):
    with open(metadata_path, encoding="utf-8") as f:
        metadata = json.load(f)
        metadata_note = f"{metadata.get('title', '')} (ç¨®é¡: {metadata.get('type', '')}, å„ªå…ˆåº¦: {metadata.get('priority', '')})"

search_corpus = faq_questions + knowledge_contents
source_flags = ["faq"] * len(faq_questions) + ["knowledge"] * len(knowledge_contents)

EMBED_MODEL = "text-embedding-3-small"
VECTOR_PATH = "data/vector_data.npy"
INDEX_PATH = "data/index.faiss"

def get_embedding(text):
    if not text or not text.strip():
        raise ValueError("ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã«ã¯åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“")
    try:
        response = client.embeddings.create(
            model=EMBED_MODEL,
            input=[text]
        )
        if not response.data or not response.data[0].embedding:
            raise ValueError("åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        return np.array(response.data[0].embedding, dtype="float32")
    except Exception as e:
        print("âŒ Embedding error:", e)
        raise

if os.path.exists(VECTOR_PATH) and os.path.exists(INDEX_PATH):
    vector_data = np.load(VECTOR_PATH)
    index = faiss.read_index(INDEX_PATH)
else:
    vector_data = np.array([get_embedding(text) for text in search_corpus], dtype="float32")
    index = faiss.IndexFlatL2(vector_data.shape[1])
    index.add(vector_data)
    np.save(VECTOR_PATH, vector_data)
    faiss.write_index(index, INDEX_PATH)

# Google Sheets
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID")
UNANSWERED_SHEET = "faq_suggestions"
FEEDBACK_SHEET = "feedback_log"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

credentials_info = json.loads(base64.b64decode(os.environ["GOOGLE_CREDENTIALS"]).decode("utf-8"))
credentials = service_account.Credentials.from_service_account_info(credentials_info, scopes=SCOPES)
sheet_service = build("sheets", "v4", credentials=credentials).spreadsheets()

pf_matcher = ProductFilmMatcher("data/product_film_color_matrix.json")

with open("system_prompt.txt", encoding="utf-8") as f:
    base_prompt = f.read()

def infer_response_mode(question):
    q_len = len(question)
    if q_len < 30:
        return "short"
    elif q_len > 100:
        return "long"
    else:
        return "default"

GREETING_PATTERNS = ["ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã°ã‚“ã¯", "ãŠã¯ã‚ˆã†", "ã¯ã˜ã‚ã¾ã—ã¦", "å®œã—ããŠé¡˜ã„ã—ã¾ã™", "ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™"]

@app.route("/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json()
        user_q = data.get("question", "").strip()
        session_id = data.get("session_id", "default")

        if not user_q:
            return jsonify({"error": "è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“"}), 400

        # æŒ¨æ‹¶ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®å³æ™‚è¿”ç­”
        if any(greet in user_q for greet in GREETING_PATTERNS):
            reply = "ã“ã‚“ã«ã¡ã¯ï¼ã”è³ªå•ãŒã‚ã‚Œã°ãŠæ°—è»½ã«ã©ã†ãã€‚"
            add_to_session_history(session_id, "assistant", reply)
            return jsonify({
                "response": reply,
                "original_question": user_q,
                "expanded_question": user_q
            })

        add_to_session_history(session_id, "user", user_q)
        session_history = get_session_history(session_id)

        q_vector = get_embedding(user_q)

        D, I = index.search(np.array([q_vector]), k=7)
        if I.shape[1] == 0:
            raise ValueError("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        faq_context = []
        reference_context = []

        for idx in I[0]:
            if idx >= len(source_flags):
                continue
            src = source_flags[idx]
            if src == "faq":
                q = faq_questions[idx]
                a = faq_answers[idx]
                faq_context.append(f"Q: {q}\nA: {a}")
            elif src == "knowledge":
                ref_idx = idx - len(faq_questions)
                if ref_idx < len(knowledge_contents):
                    reference_context.append(f"ã€å‚è€ƒçŸ¥è­˜ã€‘{knowledge_contents[ref_idx]}")

        film_match_data = pf_matcher.match(user_q, session_history)
        film_info_text = pf_matcher.format_match_info(film_match_data)
        if film_info_text:
            reference_context.insert(0, film_info_text)

        if metadata_note:
            reference_context.append(f"ã€å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã€‘{metadata_note}")

        if not faq_context and not reference_context and not film_info_text.strip():
            answer = (
                "å½“ç¤¾ã¯ã‚³ãƒ¼ãƒ’ãƒ¼è£½å“ã®å§”è¨—åŠ å·¥ã‚’å°‚é–€ã¨ã™ã‚‹ä¼šç¤¾ã§ã™ã€‚"
                "æã‚Œå…¥ã‚Šã¾ã™ãŒã€ã”è³ªå•å†…å®¹ãŒå½“ç¤¾æ¥­å‹™ã¨ç›´æ¥é–¢é€£ã®ã‚ã‚‹å†…å®¹ã‹ã©ã†ã‹ã‚’ã”ç¢ºèªã®ã†ãˆã€"
                "æ”¹ã‚ã¦ãŠå°‹ã­ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚\n\n"
                "ã”ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€å½“ç¤¾ã®ã€ãŠå•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ ã€‘ã‚ˆã‚Šã”é€£çµ¡ãã ã•ã„ã€‚"
            )
            add_to_session_history(session_id, "assistant", answer)
            return jsonify({
                "response": answer,
                "original_question": user_q,
                "expanded_question": user_q
            })

        faq_part = "\n\n".join(faq_context[:3]) if faq_context else "è©²å½“ã™ã‚‹FAQã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        ref_texts = [text for text in reference_context if "è£½å“ãƒ•ã‚£ãƒ«ãƒ ãƒ»ã‚«ãƒ©ãƒ¼æƒ…å ±" in text]
        other_refs = [text for text in reference_context if "è£½å“ãƒ•ã‚£ãƒ«ãƒ ãƒ»ã‚«ãƒ©ãƒ¼æƒ…å ±" not in text][:2]
        ref_part = "\n".join(ref_texts + other_refs)

        mode = infer_response_mode(user_q)

        prompt = f"""ä»¥ä¸‹ã¯å½“ç¤¾ã®FAQãŠã‚ˆã³å‚è€ƒæƒ…å ±ã§ã™ã€‚ã“ã‚Œã‚‰ã‚’å‚è€ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è£½é€ å…ƒã®ç«‹å ´ã§ã”å›ç­”ãã ã•ã„ã€‚

ã€FAQã€‘
{faq_part}

ã€å‚è€ƒæƒ…å ±ã€‘
{ref_part}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_q}
å›ç­”ï¼š"""

        system_prompt = base_prompt
        if mode == "short":
            system_prompt += "\n\nå¯èƒ½ãªé™ã‚Šç°¡æ½”ã‹ã¤è¦ç‚¹ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        elif mode == "long":
            system_prompt += "\n\nè©³ç´°ãªèª¬æ˜ã‚„å…·ä½“ä¾‹ã‚’å«ã‚ã¦ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"

        completion = client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
        )
        answer = completion.choices[0].message.content.strip()

        if "ç”³ã—è¨³" in answer or "æã‚Œå…¥ã‚Šã¾ã™ãŒ" in answer or "ã‚¨ãƒ©ãƒ¼" in answer:
            sheet_service.values().append(
                spreadsheetId=SPREADSHEET_ID,
                range=f"{UNANSWERED_SHEET}!A2:D",
                valueInputOption="RAW",
                body={"values": [[datetime.now().strftime("%Y-%m-%d %H:%M:%S"), user_q, "æœªå›ç­”", 1]]}
            ).execute()

        add_to_session_history(session_id, "assistant", answer)

        return jsonify({
            "response": answer,
            "original_question": user_q,
            "expanded_question": user_q
        })

    except Exception as e:
        print("[ERROR in /chat]:", e)
        return jsonify({
            "response": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            "error": str(e)
        }), 500

@app.route("/feedback", methods=["POST"])
def feedback():
    data = request.get_json()
    question = data.get("question")
    answer = data.get("answer")
    feedback_value = data.get("feedback")
    reason = data.get("reason", "")

    if not all([question, answer, feedback_value]):
        return jsonify({"error": "ä¸å®Œå…¨ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã™"}), 400

    sheet_service.values().append(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{FEEDBACK_SHEET}!A2:E",
        valueInputOption="RAW",
        body={"values": [[datetime.now().strftime("%Y-%m-%d %H:%M:%S"), question, answer, feedback_value, reason]]}
    ).execute()

    return jsonify({"status": "success"})

@app.route("/", methods=["GET"])
def home():
    return "Chatbot API is running."

if __name__ == "__main__":
    app.run(debug=True)